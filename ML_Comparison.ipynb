{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c959f6a6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea9d361",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Carrega a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f263d2fb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"classificacaoCOncluida.csv\")\n",
    "print(df.shape)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66c25e2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pre Process\n",
    "    Filtrando apenas por 'Task' e suas variaçoes \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cff6dbcf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# load english language model and create nlp object from it\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "\n",
    "\n",
    "def preprocess_stop_lemma(text):\n",
    "    # remove stop words and lemmatize the text\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "    \n",
    "    return \" \".join(filtered_tokens) \n",
    "\n",
    "def preprocess_stop(text):\n",
    "    # remove stop words \n",
    "    \n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    global totaltokens\n",
    "    global stopCount\n",
    "   \n",
    "    for token in doc:\n",
    "        if token.is_stop:\n",
    "            stopCount+=1\n",
    "            continue\n",
    "        if token.is_punct:\n",
    "            continue\n",
    "        totaltokens+=1\n",
    "        filtered_tokens.append(token.text)   \n",
    "    return \" \".join(filtered_tokens)\n",
    "def preprocess_lemma(text):\n",
    "    # lemmatize the text\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    global totalWords\n",
    "    global noChangesCount\n",
    "    for token in doc:\n",
    "        if token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "        totalWords+=1\n",
    "        if (str(token.lemma_)==str(token)):\n",
    "            noChangesCount+=1\n",
    "    return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e976e64",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Separando os dados que vamos utilizar por enquanto\n",
    "\n",
    "Separando apenas as colunas que serao utilizadas pelo algoritimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65460d4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df= df[['Name','Element_type','Category','classificationLabel']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850c8104",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df['classificationLabel'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef13385f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Filtrando apenas por 'Task' e suas variaçoes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96268689",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_ = df[df['Element_type'].str.endswith('ask')]\n",
    "df_2 = df[df['Element_type'].str.endswith('ctivity')]\n",
    "df_filtred = pd.concat([df_,df_2],axis=0)\n",
    "print(df_filtred.Element_type.value_counts())\n",
    "df_filtred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3ed05f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Retirando as inconclusivas e convertendo Postivas para 1 e negativas para 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "637c8b6f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_filtred.drop(df_filtred[(df_filtred['classificationLabel'] == 'Inconclusive')].index, inplace=True)\n",
    "df_filtred['Category'].value_counts()\n",
    "df_filtred['bclassification'] = df_filtred['classificationLabel'].apply(lambda x: 1 if x=='Positive' else 0) \n",
    "df = df_filtred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd3b792",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Lower all text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b020822b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df['Name'] = df['Name'].str.lower()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cria dataframes para cada uma das classes adicionando colunas com os textos pre processados\n",
    "\n",
    "Tambem é feita uma contagem de quantas palavras foram retiradas como stop words e quantas foram editadas pela lematizacao"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## STT"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c42b37",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "totalWords=0\n",
    "noChangesCount=0\n",
    "totaltokens=0\n",
    "stopCount=0\n",
    "df_stt = df[df['Category'].str.endswith('STT')].copy()\n",
    "df_stt['Names_clean_sl'] = df_stt['Name'].apply(preprocess_stop_lemma)\n",
    "df_stt['Names_clean_s'] = df_stt['Name'].apply(preprocess_stop)\n",
    "print('stopCount =',stopCount,'total tokens = ',totaltokens)\n",
    "df_stt['Names_clean_l'] = df_stt['Name'].apply(preprocess_lemma)\n",
    "print('NoChange = ',noChangesCount,'total words =',totalWords)\n",
    "print(df_stt['classificationLabel'].value_counts())\n",
    "df_stt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b18fa7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "totalWords=0\n",
    "noChangesCount=0\n",
    "totaltokens=0\n",
    "stopCount=0\n",
    "df_pp = df[df['Category'].str.endswith('PP')].copy()\n",
    "df_pp['Names_clean_sl'] = df_pp['Name'].apply(preprocess_stop_lemma)\n",
    "df_pp['Names_clean_s'] = df_pp['Name'].apply(preprocess_stop)\n",
    "print('stopCount =',stopCount,'total tokens = ',totaltokens)\n",
    "df_pp['Names_clean_l'] = df_pp['Name'].apply(preprocess_lemma)\n",
    "print('NoChange = ',noChangesCount,'total words =',totalWords)\n",
    "print(df_pp['classificationLabel'].value_counts())\n",
    "df_pp"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PDI"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0aac2b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "totalWords=0\n",
    "noChangesCount=0\n",
    "totaltokens=0\n",
    "stopCount=0\n",
    "df_pdi = df[df['Category'].str.endswith('PDI')].copy()\n",
    "df_pdi['Names_clean_sl'] = df_pdi['Name'].apply(preprocess_stop_lemma)\n",
    "df_pdi['Names_clean_s'] = df_pdi['Name'].apply(preprocess_stop)\n",
    "print('stopCount =',stopCount,'total tokens = ',totaltokens)\n",
    "df_pdi['Names_clean_l'] = df_pdi['Name'].apply(preprocess_lemma)\n",
    "print('NoChange = ',noChangesCount,'total words =',totalWords)\n",
    "print(df_pdi['classificationLabel'].value_counts())\n",
    "df_pdi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33541fad",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Balanceando os datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be163500",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Oversampling\n",
    "    para cada classe balanceamos os dados duplicando aleatoriamente elementos classificados na classe com menos elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9f1ad248",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def balance(auxdf,count,dominant):\n",
    "    df_overclass = auxdf[auxdf['classificationLabel']==dominant].sample(count, replace=True, random_state=2022)\n",
    "    df_False = auxdf[auxdf['classificationLabel']!=dominant]\n",
    "\n",
    "    df_balanced = pd.concat([df_overclass, df_False],axis=0)\n",
    "\n",
    "    return df_balanced.sample(frac=1, random_state=2022).reset_index(drop=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c20cc39",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "System, tools, and technologies (STT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c42b37",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "x = df_stt['classificationLabel'].value_counts()\n",
    "y = x.index\n",
    "if x[0]!=x[1]:\n",
    "    df_stt = balance(df_stt,max(x),y[1])\n",
    "print(df_stt['classificationLabel'].value_counts())\n",
    "df_stt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "PDI"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = df_pdi['classificationLabel'].value_counts()\n",
    "y = x.index\n",
    "\n",
    "if x[0]!=x[1]:\n",
    "    df_pdi = balance(df_pdi,max(x),y[1])\n",
    "print(df_pdi['classificationLabel'].value_counts())\n",
    "df_pdi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "PP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = df_pp['classificationLabel'].value_counts()\n",
    "y = x.index\n",
    "\n",
    "if x[0]!=x[1]:\n",
    "    df_pp = balance(df_pp,max(x),y[1])\n",
    "print(df_pp['classificationLabel'].value_counts())\n",
    "\n",
    "df_pp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "662a448a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Building the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8563b1df",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "## ecolher entre 'roc_auc' e 'accuracy'\n",
    "scoretipe = 'accuracy'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "ec1e06a9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "baca34c8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def bow(dfaux,colname):\n",
    "    cl1 = SVC()\n",
    "    cl2 = MultinomialNB()\n",
    "    cl3 = ComplementNB()\n",
    "    cl4 = RandomForestClassifier()\n",
    "    \n",
    "    \n",
    "    clf = Pipeline([('preprocessor',CountVectorizer()),('classifier',cl1)])\n",
    "\n",
    "    params1 = {}\n",
    "    params1['preprocessor__ngram_range'] = [(1,1),(1,2),(2,2),(1,3),(2,3),(3,3)]\n",
    "    params1['classifier'] = [cl1]\n",
    "\n",
    "    params2 = {}\n",
    "    params2['preprocessor__ngram_range'] = [(1,1),(1,2),(2,2),(1,3),(2,3),(3,3)]\n",
    "    params2['classifier'] = [cl2]\n",
    "\n",
    "    params3 = {}\n",
    "    params3['preprocessor__ngram_range'] = [(1,1),(1,2),(2,2),(1,3),(2,3),(3,3)]\n",
    "    params3['classifier'] = [cl3]\n",
    "\n",
    "    params4 = {}\n",
    "    params4['preprocessor__ngram_range'] = [(1,1),(1,2),(2,2),(1,3),(2,3),(3,3)]\n",
    "    params4['classifier'] = [cl4]\n",
    "\n",
    "    params = [params1,params2,params3,params4]\n",
    "\n",
    "    grid = GridSearchCV(clf, params ,cv=5,scoring=scoretipe)\n",
    "    grid.fit(dfaux[colname],dfaux['bclassification'])\n",
    "\n",
    "\n",
    "    return(colname,grid.best_params_,grid.best_score_,pd.DataFrame(grid.cv_results_)[['params','mean_test_score','rank_test_score']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "TFID"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7c9185dc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tfidf(dfaux,colname):\n",
    "    cl1 = SVC()\n",
    "    cl2 = MultinomialNB()\n",
    "    cl3 = ComplementNB()\n",
    "    cl4 = RandomForestClassifier()\n",
    "    \n",
    "    \n",
    "    clf = Pipeline([('preprocessor',TfidfVectorizer()),('classifier',cl1)])\n",
    "\n",
    "    params1 = {}\n",
    "    params1['preprocessor__ngram_range'] = [(1,1),(1,2),(2,2),(1,3),(2,3),(3,3)]\n",
    "    params1['classifier'] = [cl1]\n",
    "\n",
    "    params2 = {}\n",
    "    params2['preprocessor__ngram_range'] = [(1,1),(1,2),(2,2),(1,3),(2,3),(3,3)]\n",
    "    params2['classifier'] = [cl2]\n",
    "\n",
    "    params3 = {}\n",
    "    params3['preprocessor__ngram_range'] = [(1,1),(1,2),(2,2),(1,3),(2,3),(3,3)]\n",
    "    params3['classifier'] = [cl3]\n",
    "\n",
    "    params4 = {}\n",
    "    params4['preprocessor__ngram_range'] = [(1,1),(1,2),(2,2),(1,3),(2,3),(3,3)]\n",
    "    params4['classifier'] = [cl4]\n",
    "\n",
    "    params = [params1,params2,params3,params4]\n",
    "    \n",
    "\n",
    "    grid = GridSearchCV(clf, params ,cv=5,scoring=scoretipe)\n",
    "    grid.fit(dfaux[colname],dfaux['bclassification'])\n",
    "    \n",
    "    return colname, grid.best_params_, grid.best_score_, pd.DataFrame(grid.cv_results_)[['params', 'mean_test_score', 'rank_test_score']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Executa os testes (avaliando conforme escolhido) para todas as combinacoes de tecnicas e registra em arquivos separados"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "80de2514",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDI,BOW,Name,MultinomialNB(),(1, 2),0.9237500000000001\n",
      "PDI,TF_IDF,Name,MultinomialNB(),(1, 2),0.9237500000000001\n",
      "PP, BOW,Name,SVC(),(1, 1),0.8882807017543859\n",
      "PP, TF_IDF,Name,SVC(),(1, 1),0.8882807017543859\n",
      "STT, BOW,Name,RandomForestClassifier(),(1, 3),0.9417176372015081\n",
      "STT, TF_IDF,Name,RandomForestClassifier(),(1, 3),0.9417176372015081\n",
      "PDI,BOW,Names_clean_sl,MultinomialNB(),(1, 2),0.92875\n",
      "PDI,TF_IDF,Names_clean_sl,MultinomialNB(),(1, 2),0.92875\n",
      "PP, BOW,Names_clean_sl,RandomForestClassifier(),(1, 1),0.8989473684210527\n",
      "PP, TF_IDF,Names_clean_sl,RandomForestClassifier(),(1, 1),0.8936491228070175\n",
      "STT, BOW,Names_clean_sl,RandomForestClassifier(),(2, 2),0.9520821114369502\n",
      "STT, TF_IDF,Names_clean_sl,RandomForestClassifier(),(2, 3),0.952073732718894\n",
      "PDI,BOW,Names_clean_s,MultinomialNB(),(1, 2),0.9299999999999999\n",
      "PDI,TF_IDF,Names_clean_s,MultinomialNB(),(1, 2),0.9299999999999999\n",
      "PP, BOW,Names_clean_s,RandomForestClassifier(),(1, 1),0.8963508771929825\n",
      "PP, TF_IDF,Names_clean_s,RandomForestClassifier(),(1, 1),0.8883508771929824\n",
      "STT, BOW,Names_clean_s,RandomForestClassifier(),(2, 2),0.9507834101382489\n",
      "STT, TF_IDF,Names_clean_s,RandomForestClassifier(),(2, 2),0.952073732718894\n",
      "PDI,BOW,Names_clean_l,MultinomialNB(),(1, 2),0.9237499999999998\n",
      "PDI,TF_IDF,Names_clean_l,MultinomialNB(),(1, 2),0.9237499999999998\n",
      "PP, BOW,Names_clean_l,SVC(),(1, 1),0.8962456140350877\n",
      "PP, TF_IDF,Names_clean_l,RandomForestClassifier(),(1, 1),0.9042807017543859\n",
      "STT, BOW,Names_clean_l,RandomForestClassifier(),(1, 2),0.9495182237117721\n",
      "STT, TF_IDF,Names_clean_l,RandomForestClassifier(),(1, 2),0.9455886049434437\n"
     ]
    }
   ],
   "source": [
    "for x in ['Name', 'Names_clean_sl', 'Names_clean_s', 'Names_clean_l']:\n",
    "    pre,params,result,df_saida = bow(df_pdi,x)\n",
    "    print(f'PDI,BOW,{pre},{params[\"classifier\"]},{params[\"preprocessor__ngram_range\"]},{result}')\n",
    "    df_saida.to_csv(scoretipe+'/PDI BOW '+pre+'.csv',index=False)\n",
    "\n",
    "    pre,params,result,df_saida = bow(df_pdi,x)\n",
    "    print(f'PDI,TF_IDF,{pre},{params[\"classifier\"]},{params[\"preprocessor__ngram_range\"]},{result}')\n",
    "    df_saida.to_csv(scoretipe+'/PDI TF-IDF '+pre+'.csv',index=False)\n",
    "\n",
    "    pre,params,result,df_saida = bow(df_pp,x)\n",
    "    print(f'PP, BOW,{pre},{params[\"classifier\"]},{params[\"preprocessor__ngram_range\"]},{result}')\n",
    "    df_saida.to_csv(scoretipe+'/PP BOW '+pre+'.csv',index=False)\n",
    "\n",
    "    pre,params,result,df_saida = bow(df_pp,x)\n",
    "    print(f'PP, TF_IDF,{pre},{params[\"classifier\"]},{params[\"preprocessor__ngram_range\"]},{result}')\n",
    "    df_saida.to_csv(scoretipe+'/PP TF-IDF '+pre+'.csv',index=False)\n",
    "\n",
    "    pre,params,result,df_saida = bow(df_stt,x)\n",
    "    print(f'STT, BOW,{pre},{params[\"classifier\"]},{params[\"preprocessor__ngram_range\"]},{result}')\n",
    "    df_saida.to_csv(scoretipe+'/STT BOW '+pre+'.csv',index=False)\n",
    "\n",
    "    pre,params,result,df_saida = bow(df_stt,x)\n",
    "    print(f'STT, TF_IDF,{pre},{params[\"classifier\"]},{params[\"preprocessor__ngram_range\"]},{result}')\n",
    "    df_saida.to_csv(scoretipe+'/STT TF-IDF '+pre+'.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Concatenando as diferentes saidas em um unico arquivo para roc_auc e Accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "accuracy_list = os.listdir('accuracy')\n",
    "roc_auc_list = os.listdir('roc_auc')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "def agrupar_saidas(lista,pasta):\n",
    "    colunas = ['class','algorithm','textPreprocess']\n",
    "    df_completo = pd.DataFrame()\n",
    "    for arquivo in lista:\n",
    "        df_parcial = pd.read_csv(pasta+'/'+arquivo)\n",
    "        arquivo = arquivo.replace('.csv',' ')\n",
    "        padroes_do_arquivo = arquivo.split()\n",
    "        for ind,col in enumerate(padroes_do_arquivo):\n",
    "            df_parcial[colunas[ind]] = col\n",
    "        df_completo = pd.concat([df_completo,df_parcial],axis=0)\n",
    "\n",
    "    df_completo.to_csv(f'results_{pasta}_completo.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "agrupar_saidas(accuracy_list,\"accuracy\")\n",
    "agrupar_saidas(roc_auc_list,\"roc_auc\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Executa novo treino com os melhores casos de n-gramas em cada combinaçao classe - algoritimo para gerar grafico"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "def split(names_column,df_class):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df_class[names_column],\n",
    "        df_class['bclassification'],\n",
    "        test_size=0.2, # 20% samples will go to test dataset\n",
    "        stratify=df_class['bclassification'],\n",
    "        random_state=1873211\n",
    "        )\n",
    "    return X_train, X_test, y_train, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "def tfidf2(X_train, X_test, y_train, y_test,classe,best):\n",
    "\n",
    "    models = [MultinomialNB(),ComplementNB(),RandomForestClassifier(),SVC()]\n",
    "    names = ['MultinomialNB','ComplementNB','RFC','SVC']\n",
    "    for name,mod in enumerate(models):\n",
    "        v = TfidfVectorizer(ngram_range=best[str(mod)])\n",
    "        X_train_count = v.fit_transform(X_train.values)\n",
    "        model = mod\n",
    "        model.fit(X_train_count,y_train)\n",
    "\n",
    "\n",
    "        X_test_count = v.transform( X_test)\n",
    "        svc_disp = RocCurveDisplay.from_estimator(model, X_test_count, y_test, ax=ax,name=classe + names[name] +str(best[str(mod)]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_stt.name='STT '\n",
    "df_pp.name='PP '\n",
    "df_pdi.name='PDI '\n",
    "dfs = [df_stt,df_pp,df_pdi]\n",
    "\n",
    "#selecionar o numero de ngramas que apresentaram melhor desempenho para cada algoritimo em cada classe\n",
    "bestpdi= {'MultinomialNB()':(1,2),'ComplementNB()':(1,2),'RandomForestClassifier()':(1,1),'SVC()':(1,1)}\n",
    "bestpp = {'MultinomialNB()':(1,2),'ComplementNB()':(2,2),'RandomForestClassifier()':(1,1),'SVC()':(1,1)}\n",
    "beststt = {'MultinomialNB()':(1,3),'ComplementNB()':(2,3),'RandomForestClassifier()':(2,2),'SVC()':(1,3)}\n",
    "bests = [beststt,bestpp,bestpdi]\n",
    "plt.figure(figsize=[5.5,4],frameon=False)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_facecolor(\"white\")\n",
    "\n",
    "\n",
    "\n",
    "for x,df_ in enumerate(dfs):\n",
    "    X_train, X_test, y_train, y_test = split('Names_clean_sl',df_)\n",
    "    tfidf2(X_train, X_test, y_train, y_test,df_.name,bests[x])\n",
    "plt.grid(color='#ececec')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(facecolor=\"white\")\n",
    "ax.spines['bottom'].set_color('#4d4d4d')\n",
    "ax.spines['top'].set_color('#4d4d4d')\n",
    "ax.xaxis.label.set_color('#4d4d4d')\n",
    "ax.tick_params(axis='x', colors='#4d4d4d')\n",
    "\n",
    "ax.spines['left'].set_color('#4d4d4d')\n",
    "ax.spines['right'].set_color('#4d4d4d')\n",
    "ax.xaxis.label.set_color('#4d4d4d')\n",
    "ax.tick_params(axis='y', colors='#4d4d4d')\n",
    "\n",
    "plt.savefig('line_plot.pdf')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}